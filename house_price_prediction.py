# -*- coding: utf-8 -*-
"""House_Price Prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OwtKEaHPeiKVS31HH_-I0M40hGZRHXW5
"""

#!/usr/bin/env python3
"""
House Price Prediction (California Housing example)

This script loads a housing dataset (scikit-learn's California Housing),
preprocesses features, trains a regression model (Linear Regression by default),
and reports evaluation metrics (MSE, RMSE, MAE, R^2) on a held-out test set.

Usage:
    python house_price_prediction.py
    python house_price_prediction.py --model rf --test-size 0.25 --random-state 1
    python house_price_prediction.py --model linear --save house_model.joblib

Options:
    --model        Model to train: 'linear' (LinearRegression) or 'rf' (RandomForestRegressor). Default: linear
    --test-size    Fraction of data used as test set (float in (0,1]). Default: 0.2
    --random-state Integer random seed. Default: 42
    --save         Optional path to save trained pipeline (joblib)
    --cv           If provided, runs simple cross-validation (int folds). Default: not run
    --verbose      Increase logging output
"""

import argparse
import joblib
import numpy as np
import pandas as pd
import os
import sys
from sklearn.datasets import fetch_california_housing  # Changed from fetch_openml(name="Boston")
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error # Added mean_absolute_error

MODEL_PATH = "house_price_model.joblib"

def load_california_housing(): # Renamed function
    """
    Fetch California Housing dataset from scikit-learn. Returns (X_df, y_series, feature_names).
    """
    print("Fetching California Housing dataset...")
    data = fetch_california_housing(as_frame=True) # Use as_frame=True
    X = data.frame.drop(columns=["MedHouseVal"]) # Drop target column from features
    y = data.frame["MedHouseVal"] # Get target column
    feature_names = data.feature_names
    print(f"Loaded dataset with {X.shape[0]} rows and {X.shape[1]} features.")
    return X, y, list(X.columns)

def build_preprocessing_pipeline(model):
    """
    Create a pipeline with imputation, scaling, and the supplied model.
    """
    pipe = Pipeline([
        ("imputer", SimpleImputer(strategy="median")), # Using median strategy
        ("scaler", StandardScaler()),
        ("model", model)
    ])
    return pipe

def evaluate_model(pipe, X_train, X_test, y_train, y_test, name="model"):
    """
    Fit and evaluate the pipeline, printing MSE, RMSE, MAE, and R^2. # Added MAE
    """
    pipe.fit(X_train, y_train)
    preds = pipe.predict(X_test)
    mse = mean_squared_error(y_test, preds)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, preds) # Added MAE calculation
    r2 = r2_score(y_test, preds)
    print(f"\n=== Evaluation: {name} ===")
    print(f"MSE : {mse:.4f}")
    print(f"RMSE: {rmse:.4f}")
    print(f"MAE : {mae:.4f}") # Added MAE printing
    print(f"R^2 : {r2:.4f}")
    return pipe, {"mse": mse, "rmse": rmse, "mae": mae, "r2": r2} # Added MAE to returned metrics

def predict_from_csv_string(pipe, csv_string, feature_names):
    """
    Accept a comma-separated string of feature values (in the same order as feature_names),
    convert to a 1-row DataFrame, and predict.
    """
    parts = [p.strip() for p in csv_string.split(",")]
    if len(parts) != len(feature_names):
        raise ValueError(f"Expected {len(feature_names)} values (features), got {len(parts)}.")
    vals = []
    for p in parts:
        try:
            vals.append(float(p))
        except ValueError:
            vals.append(np.nan)
    df = pd.DataFrame([vals], columns=feature_names)
    # Ensure column order matches training data, impute and scale before prediction
    # This requires accessing the imputer and scaler from the trained pipeline
    processed_df = pipe.named_steps['imputer'].transform(df)
    processed_df = pipe.named_steps['scaler'].transform(processed_df)
    pred = pipe.named_steps['model'].predict(processed_df)[0] # Predict using the trained model
    return pred


def interactive_prompt(pipe, feature_names):
    """
    Interactive CLI: user types comma-separated feature values in the correct order.
    """
    print("\nInteractive prediction mode.")
    print("Enter feature values as a comma-separated list in the following order:")
    print(", ".join(feature_names))
    # Updated example values for California Housing features
    print("Example (first few values): 8.3252, 41.0, 6.9841267, 1.0238095, 322.0, ...")
    print("Type 'exit' or 'quit' to leave.\n")
    while True:
        try:
            s = input("> ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\nExiting interactive mode.")
            break
        if not s:
            continue
        if s.lower() in {"exit", "quit"}:
            print("Exiting interactive mode.")
            break
        try:
            pred = predict_from_csv_string(pipe, s, feature_names)
            print(f"Predicted house value (median): {pred:.3f}") # Updated output text
        except Exception as e:
            print(f"Error: {e}")
            print("Make sure you provided comma-separated numeric values matching feature order.")

def main(args):
    X, y, feature_names = load_california_housing() # Call the new function

    # Quick exploration summary
    print("\nDataset preview:")
    print(X.head())
    print("\nTarget preview (first 5):")
    print(y.head())

    # Train/test split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    print(f"\nTrain size: {len(X_train)}, Test size: {len(X_test)}")

    # Build and evaluate Linear Regression
    lr = LinearRegression()
    lr_pipe = build_preprocessing_pipeline(lr)
    lr_pipe, lr_metrics = evaluate_model(lr_pipe, X_train, X_test, y_train, y_test, name="LinearRegression")

    # Build and evaluate Random Forest (comparison)
    rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
    rf_pipe = build_preprocessing_pipeline(rf)
    rf_pipe, rf_metrics = evaluate_model(rf_pipe, X_train, X_test, y_train, y_test, name="RandomForestRegressor")

    # Decide active model (use LinearRegression by default; you may switch)
    active_pipe = lr_pipe
    print("\nSaving the LinearRegression pipeline to disk as:", MODEL_PATH)
    joblib.dump({"pipeline": active_pipe, "feature_names": feature_names}, MODEL_PATH)

    # If a single prediction string provided via --predict, do it and exit (unless interactive flag set)
    if args.predict:
        try:
            pred = predict_from_csv_string(active_pipe, args.predict, feature_names)
            print(f"\nPrediction for provided input: {pred:.3f}")
        except Exception as e:
            print("Error parsing --predict string:", e)

    # Interactive mode
    if args.interactive:
        interactive_prompt(active_pipe, feature_names)

if __name__ == "__main__":
    # Check if running in an interactive environment (like Colab)
    if 'ipykernel' in sys.modules:
        # If in interactive environment, run main directly without argument parsing
        # You can pass default arguments here or define them interactively
        class Args:
            interactive = False
            predict = ""
        main(Args())
    else:
        # If not in interactive environment, parse command-line arguments
        parser = argparse.ArgumentParser(description="Train a house price model on the Boston dataset.")
        parser.add_argument("--interactive", action="store_true", help="Start an interactive prompt to input features for prediction.")
        parser.add_argument("--predict", type=str, default="", help="Provide a comma-separated list of feature values to predict once.")
        args = parser.parse_args()
        main(args)